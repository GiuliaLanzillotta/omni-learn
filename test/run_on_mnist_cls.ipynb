{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, time\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as distrib\n",
    "import torch.multiprocessing as mp\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gym\n",
    "import numpy as np\n",
    "%matplotlib notebook\n",
    "#%matplotlib tk\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.switch_backend('Qt5Agg') #('Qt5Agg')\n",
    "import foundation as fd\n",
    "from foundation import models\n",
    "from foundation import util\n",
    "from foundation import train\n",
    "\n",
    "np.set_printoptions(linewidth=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = train.setup_standard_options(no_config=True)\n",
    "\n",
    "args = parser.parse_args([])\n",
    "\n",
    "args.no_test = True\n",
    "\n",
    "args.device = 'cuda:0'\n",
    "args.seed = 0\n",
    "\n",
    "args.logdate = True\n",
    "args.tblog = False\n",
    "args.txtlog = False\n",
    "args.saveroot = 'trained_nets'\n",
    "args.save_freq = -1\n",
    "\n",
    "args.dataset = 'svhn'\n",
    "# args.dataset = 'mnist'\n",
    "# for emnist change link: 'http://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/gzip.zip'\n",
    "args.use_val = True\n",
    "args.val_per = 1/6\n",
    "\n",
    "args.num_workers = 4\n",
    "args.batch_size = 128\n",
    "\n",
    "args.start_epoch = 0\n",
    "args.epochs = 10\n",
    "\n",
    "args.name = 'test_on_mnist'\n",
    "\n",
    "\n",
    "now = time.strftime(\"%y-%m-%d-%H%M%S\")\n",
    "if args.logdate:\n",
    "    args.name = os.path.join(args.name, now)\n",
    "args.save_dir = os.path.join(args.saveroot, args.name)\n",
    "print('Save dir: {}'.format(args.save_dir))\n",
    "\n",
    "if args.tblog or args.txtlog:\n",
    "    util.create_dir(args.save_dir)\n",
    "    print('Logging in {}'.format(args.save_dir))\n",
    "logger = util.Logger(args.save_dir, tensorboard=args.tblog, txt=args.txtlog)\n",
    "\n",
    "# Set seed\n",
    "if not hasattr(args, 'seed') or args.seed is None:\n",
    "    args.seed = util.get_random_seed()\n",
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "try:\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    args.device = 'cpu'\n",
    "print('Using device {} - random seed set to {}'.format(args.device, args.seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasets = train.load_data(args=args)\n",
    "shuffles = [True, False, False]\n",
    "\n",
    "loaders = [DataLoader(d, batch_size=args.batch_size, num_workers=args.num_workers) for d, s in zip(datasets, shuffles)]\n",
    "\n",
    "trainloader, testloader = loaders[0], loaders[-1]\n",
    "valloader = None if len(loaders) == 2 else loaders[1]\n",
    "\n",
    "print('Input: {}, Output: {}'.format(args.din, args.dout))\n",
    "print('traindata len={}, trainloader len={}'.format(len(datasets[0]), len(trainloader)))\n",
    "if valloader is not None:\n",
    "    print('valdata len={}, valloader len={}'.format(len(datasets[1]), len(valloader)))\n",
    "print('testdata len={}, testloader len={}'.format(len(datasets[-1]), len(testloader)))\n",
    "print('Batch size: {} samples'.format(args.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "args.total_samples = {'train': 0, 'val':0, 'test': 0}\n",
    "epoch = 0\n",
    "best_loss = None\n",
    "all_train_stats = []\n",
    "all_val_stats = []\n",
    "all_test_stats = []\n",
    "\n",
    "args.din_flat = int(np.product(args.din))\n",
    "\n",
    "class Simple(fd.Visualizable, fd.Trainable_Model):\n",
    "    def __init__(self, net):\n",
    "        super().__init__(args.din, args.dout)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.net = net\n",
    "        \n",
    "        self.stats.new('confidence', 'accuracy')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "    def _visualize(self, info, logger=None):\n",
    "        \n",
    "        conf, pick = info.pred.max(-1)\n",
    "\n",
    "        confidence = conf.detach()\n",
    "        correct = pick.sub(info.y).eq(0).float().detach()\n",
    "\n",
    "        self.stats.update('confidence', confidence.mean())\n",
    "        self.stats.update('accuracy', correct.mean())\n",
    "    \n",
    "    def _step(self, batch, out=None):\n",
    "        if out is None:\n",
    "            out = util.TensorDict()\n",
    "            \n",
    "        x,y = batch\n",
    "        \n",
    "        pred = self(x)\n",
    "        \n",
    "        loss = self.criterion(pred, y)\n",
    "        \n",
    "        if self.train_me():\n",
    "            self.optim.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optim.step()\n",
    "            \n",
    "        out.loss = loss\n",
    "        out.x = x\n",
    "        out.y = y\n",
    "        out.pred = pred\n",
    "        return out\n",
    "    \n",
    "\n",
    "net = nn.Sequential(nn.Flatten(), models.make_MLP(args.din_flat, args.dout, hidden_dims=[], nonlin='prelu'))\n",
    "\n",
    "model = Simple(net)\n",
    "model.set_optim(optim_type='adam', lr=1e-3, weight_decay=1e-4, momentum=0.9)\n",
    "scheduler = None#torch.optim.lr_scheduler.StepLR(optim, step_size=6, gamma=0.2)\n",
    "\n",
    "model.to(args.device)\n",
    "print(model)\n",
    "print(model.optim)\n",
    "print('Model has {} parameters'.format(util.count_parameters(model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reseed after model init\n",
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "try:\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "if args.no_test:\n",
    "    print('Will not run test data after training')\n",
    "else:\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(args.epochs):\n",
    "\n",
    "    model.reset()\n",
    "\n",
    "    train_stats = util.StatsMeter()\n",
    "    train_stats.shallow_join(model.stats)\n",
    "\n",
    "    train_stats = train.run_epoch(model, trainloader, args, mode='train',\n",
    "                                  epoch=epoch, print_freq=args.print_freq, logger=logger, silent=True,\n",
    "                                  viz_criterion_args=args.viz_criterion_args,\n",
    "                                  stats=train_stats, )\n",
    "\n",
    "    all_train_stats.append(train_stats.copy())\n",
    "\n",
    "    if valloader is not None:\n",
    "        model.reset()\n",
    "\n",
    "        val_stats = util.StatsMeter()\n",
    "        val_stats.shallow_join(model.stats)\n",
    "\n",
    "        val_stats = train.run_epoch(model, valloader, args, mode='val',\n",
    "                                  epoch=epoch, print_freq=args.print_freq, logger=logger, silent=True,\n",
    "                                  viz_criterion_args=args.viz_criterion_args,\n",
    "                                  stats=val_stats, )\n",
    "\n",
    "        all_val_stats.append(val_stats.copy())\n",
    "\n",
    "    print('[ {} ] Epoch {} Train={:.3f} ({:.3f}), Val={:.3f} ({:.3f})'.format(\n",
    "        time.strftime(\"%H:%M:%S\"), epoch+1,\n",
    "        train_stats['accuracy'].avg.item(), train_stats['loss'].avg.item(),\n",
    "        val_stats['accuracy'].avg.item(), val_stats['loss'].avg.item(),\n",
    "    ))\n",
    "\n",
    "    if args.save_freq > 0 and epoch % args.save_freq == 0:\n",
    "\n",
    "\n",
    "        ckpt = {\n",
    "            'epoch': epoch+1,\n",
    "\n",
    "            'args': args,\n",
    "\n",
    "            'model_str': str(model),\n",
    "            'model_state': model.state_dict(),\n",
    "            'all_train_stats': all_train_stats,\n",
    "        }\n",
    "        if args.track_best:\n",
    "            av_loss = train_stats['loss'].avg.item() if valloader is None else val_stats['loss'].avg.item()\n",
    "            is_best = best_loss is None or av_loss < best_loss\n",
    "            if is_best:\n",
    "                best_loss = av_loss\n",
    "                best_epoch = epoch\n",
    "\n",
    "            ckpt['loss'] = av_loss\n",
    "            ckpt['best_loss'] = best_loss\n",
    "            ckpt['best_epoch'] = best_epoch\n",
    "        if len(all_val_stats):\n",
    "            ckpt['all_val_stats'] = all_val_stats\n",
    "        path = save_checkpoint(ckpt, args.save_dir, is_best=is_best, epoch=epoch+1)\n",
    "        print('--- checkpoint saved to {} ---'.format(path))\n",
    "\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_key = 'accuracy'\n",
    "\n",
    "figax = None\n",
    "figax = util.plot_stat(all_train_stats, key=stat_key, figax=figax, label='train')\n",
    "figax = util.plot_stat(all_val_stats, key=stat_key, figax=figax, label='val')\n",
    "fig, ax = figax\n",
    "plt.sca(ax)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel(stat_key)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
